{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Project work in Deep Learning </center> </h1> \n",
    "<h2> <center> Song Lyrics Classification Based on Genres </center> </h2>\n",
    "\n",
    "<h3> Student: Dinno Koluh (0001034376)</h3>\n",
    "\n",
    "<h4> Introduction </h4>\n",
    "<p>\n",
    "In this project we are going classify songs into genres based on their lyrics. This is inherently a task in the area of NLP (Natural Language Processing), more specifically the <i>text classification</i> problem. In our case the text to be classified is the song lyrics and the different classes are the different genres. This task has substantial real-world usage application as the big music platforms (e.g. Spotify, Deezer, SoundCloud, Apple Music...) are exposed to this task on a daily basis. \n",
    "</p>\n",
    "\n",
    "<h4> Dataset </h4>\n",
    "\n",
    "The used dataset was obtained from Kaggle (it can be found <a url=\"https://www.kaggle.com/datasets/mateibejan/multilingual-lyrics-for-genre-classification\"> here</a>). The dataset is comprised of ~300,000 samples with the following features: artist, song title, genre, language, lyrics. During the preprocessing phase we are going to address the issues and solutions in the dataset. \n",
    "\n",
    "<h4> Architecture to be used </h4>\n",
    "\n",
    "To go-to architecture for NLP tasks used to be RNN (Recurrent Neural Networks) and their modifications (LSTM, GRU) as we are dealing with inherently sequential data. RNNs are able to capture contextual information as they are able to store information from previous inputs. But this fact is also the bottleneck as RNNs have long-term dependency issues (information about a fact stated at the beginning of a document is lost at some point) and they are inefficient when training as it is hard to parallelize them to use the massive power of GPUs for training. \n",
    "\n",
    "Nowadays the most popular architecture used in NLP tasks is the Transformer. The two problems RNNs had, the Transformer model solves using the <i> attention </i> mechanism which enables to capture dependencies between distant words in text and input sequences can be processed in parallel making the Transformer model highly efficient. We are going to dive more into the architecture of the Transformer when we start to build the model for the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import contractions\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Data preprocessing </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Song</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Language</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12 stones</td>\n",
       "      <td>world so cold</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>It starts with pain, followed by hate\\nFueled ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12 stones</td>\n",
       "      <td>broken</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>Freedom!\\nAlone again again alone\\nPatiently w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12 stones</td>\n",
       "      <td>3 leaf loser</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>Biting the hand that feeds you, lying to the v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12 stones</td>\n",
       "      <td>anthem for the underdog</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>You say you know just who I am\\nBut you can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 stones</td>\n",
       "      <td>adrenaline</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>My heart is beating faster can't control these...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291117</th>\n",
       "      <td>bobby womack</td>\n",
       "      <td>i wish he didn t trust me so much</td>\n",
       "      <td>R&amp;B</td>\n",
       "      <td>en</td>\n",
       "      <td>I'm the best friend he's got I'd give him the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291118</th>\n",
       "      <td>bad boys blue</td>\n",
       "      <td>i totally miss you</td>\n",
       "      <td>Pop</td>\n",
       "      <td>en</td>\n",
       "      <td>Bad Boys Blue \"I Totally Miss You\" I did you w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291119</th>\n",
       "      <td>celine dion</td>\n",
       "      <td>sorry for love</td>\n",
       "      <td>Pop</td>\n",
       "      <td>en</td>\n",
       "      <td>Forgive me for the things That I never said to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291120</th>\n",
       "      <td>dan bern</td>\n",
       "      <td>cure for aids</td>\n",
       "      <td>Indie</td>\n",
       "      <td>en</td>\n",
       "      <td>The day they found a cure for AIDS The day the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291121</th>\n",
       "      <td>crawdad republic</td>\n",
       "      <td>iceberg meadows</td>\n",
       "      <td>Pop</td>\n",
       "      <td>en</td>\n",
       "      <td>Fourth of July has come, it's custom that we g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291122 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Artist                               Song  Genre Language   \n",
       "0              12 stones                      world so cold   Rock       en  \\\n",
       "1              12 stones                             broken   Rock       en   \n",
       "2              12 stones                       3 leaf loser   Rock       en   \n",
       "3              12 stones            anthem for the underdog   Rock       en   \n",
       "4              12 stones                         adrenaline   Rock       en   \n",
       "...                  ...                                ...    ...      ...   \n",
       "291117      bobby womack  i wish he didn t trust me so much    R&B       en   \n",
       "291118     bad boys blue                 i totally miss you    Pop       en   \n",
       "291119       celine dion                     sorry for love    Pop       en   \n",
       "291120          dan bern                      cure for aids  Indie       en   \n",
       "291121  crawdad republic                    iceberg meadows    Pop       en   \n",
       "\n",
       "                                                   Lyrics  \n",
       "0       It starts with pain, followed by hate\\nFueled ...  \n",
       "1       Freedom!\\nAlone again again alone\\nPatiently w...  \n",
       "2       Biting the hand that feeds you, lying to the v...  \n",
       "3       You say you know just who I am\\nBut you can't ...  \n",
       "4       My heart is beating faster can't control these...  \n",
       "...                                                   ...  \n",
       "291117  I'm the best friend he's got I'd give him the ...  \n",
       "291118  Bad Boys Blue \"I Totally Miss You\" I did you w...  \n",
       "291119  Forgive me for the things That I never said to...  \n",
       "291120  The day they found a cure for AIDS The day the...  \n",
       "291121  Fourth of July has come, it's custom that we g...  \n",
       "\n",
       "[291122 rows x 5 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only work on songs in English, so we will keep only samples in English. After this step we can also drop the language columns as it not necessary anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df_train = df_train[df_train[\"Language\"] == 'en'] # removing language\n",
    "df_train = en_df_train.drop(columns='Language') # language column now more needed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now get the unique genres in the genre columns. There will be some noisy data, so we will filter it and jest keep the genres that make sense. We will construct a dictionary where the keys will be the genres and the values are the dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rock' 'Metal' 'Pop' 'Indie' 'Folk' 'Electronic' 'R&B' 'Jazz' 'Hip-Hop'\n",
      " 'Country']\n",
      "Number of training samples: 242028\n",
      "Number of test samples: 7440\n"
     ]
    }
   ],
   "source": [
    "genres = df_train['Genre'].unique() # there is some noisy data\n",
    "print(genres)\n",
    "genres = ['Rock', 'Metal', 'Pop', 'Indie', 'R&B', 'Electronic', 'Jazz', 'Hip-Hop', 'Country'] # the genres that we will keep\n",
    "\n",
    "data_train = {} # dictionary of genres used as keys\n",
    "data_test = {}\n",
    "train_samples = 0 # number of samples\n",
    "test_samples = 0\n",
    "for g in genres:\n",
    "    data_train[g] = df_train[df_train[\"Genre\"] == g]\n",
    "    data_test[g] = df_test[df_test[\"Genre\"] == g]\n",
    "    train_samples += len(data_train[g])\n",
    "    test_samples += len(data_test[g])\n",
    "print(\"Number of training samples: \" + str(train_samples))\n",
    "print(\"Number of test samples: \" + str(test_samples))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now inspect the obtained data. For training purposes we should have balanced data across the different classes. So, let us see how classes compare to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music genre: Rock. Number of samples: 107145. Percentage of dataset: 44.26967127770341.\n",
      "\n",
      "Music genre: Metal. Number of samples: 19133. Percentage of dataset: 7.9052836861850695.\n",
      "\n",
      "Music genre: Pop. Number of samples: 86298. Percentage of dataset: 35.65620506718231.\n",
      "\n",
      "Music genre: Indie. Number of samples: 7240. Percentage of dataset: 2.9913894260168243.\n",
      "\n",
      "Music genre: R&B. Number of samples: 2765. Percentage of dataset: 1.142429801510569.\n",
      "\n",
      "Music genre: Electronic. Number of samples: 2005. Percentage of dataset: 0.8284165468458194.\n",
      "\n",
      "Music genre: Jazz. Number of samples: 13314. Percentage of dataset: 5.50101641132431.\n",
      "\n",
      "Music genre: Hip-Hop. Number of samples: 2238. Percentage of dataset: 0.9246863999206704.\n",
      "\n",
      "Music genre: Country. Number of samples: 1890. Percentage of dataset: 0.7809013833110219.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_data(data, n_samples):\n",
    "    for key in data.keys():\n",
    "        print(\"Music genre: {}. Number of samples: {}. Percentage of dataset: {}.\\n\".format(key, len(data[key]), 100*len(data[key])/n_samples))\n",
    "print_data(data_train, train_samples)\n",
    "# print_data(data_test, test_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the data is unbalanced to a great extent. Rock and Pop are the most present genres whereas Country and Electronic music are the least present. To keep data at a large enough level, we will drop the Country and Electronic genres and downsize other genres to about $2500$ random samples to keep the dataset balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting the two least present genres\n",
    "del data_train['Electronic']\n",
    "del data_train['Country']\n",
    "del data_test['Electronic']\n",
    "del data_test['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new number of samples after deleting Electronic and Country genres\n",
    "train_samples = 0\n",
    "test_samples = 0\n",
    "for key in data_train.keys(): train_samples+=len(data_train[key])\n",
    "for key in data_test.keys(): test_samples+=len(data_test[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music genre: Rock. Number of samples: 2500. Percentage of dataset: 14.5028425571412.\n",
      "\n",
      "Music genre: Metal. Number of samples: 2500. Percentage of dataset: 14.5028425571412.\n",
      "\n",
      "Music genre: Pop. Number of samples: 2500. Percentage of dataset: 14.5028425571412.\n",
      "\n",
      "Music genre: Indie. Number of samples: 2500. Percentage of dataset: 14.5028425571412.\n",
      "\n",
      "Music genre: R&B. Number of samples: 2500. Percentage of dataset: 14.5028425571412.\n",
      "\n",
      "Music genre: Jazz. Number of samples: 2500. Percentage of dataset: 14.5028425571412.\n",
      "\n",
      "Music genre: Hip-Hop. Number of samples: 2238. Percentage of dataset: 12.982944657152801.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genres = ['Rock', 'Metal', 'Pop', 'Indie', 'R&B', 'Jazz', 'Hip-Hop'] # the genres that we will keep\n",
    "train_samples = 0\n",
    "for g in genres:\n",
    "    if g == 'Hip-Hop': \n",
    "        train_samples += len(data_train[g])\n",
    "        continue\n",
    "    data_train[g] = data_train[g].sample(n=2500, random_state=0)\n",
    "    train_samples += len(data_train[g])\n",
    "print_data(data_train, train_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a decently balanced dataset, so we can proceed with some text preprocessing. Let us look at the lyrics of the first rock song to get the idea of the text we are working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me that you've got everything you want\n",
      "But you don't get me\n",
      "You say you've seen seven wonders\n",
      "And you're bird is green\n",
      "But you don't see me\n",
      "When your prized possessions start to weigh you down\n",
      "Look in my direction,\n",
      "I'll be 'round\n",
      "I'll be 'round\n",
      "When your bird is broken\n",
      "Will it bring you down\n",
      "You may feel awoken\n",
      "I'll be 'round\n",
      "I'll be 'round\n",
      "You tell me that you've heard every sound there is\n",
      "And your bird can swing\n",
      "But you don't get me\n",
      "You can't hear me.\n"
     ]
    }
   ],
   "source": [
    "print(data_train['Rock']['Lyrics'].iloc[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now normalize the text. We are going to do the following:\n",
    "<br>\n",
    "- Tokenize the text\n",
    "- Expand token contractions ('cause $\\rightarrow$ because)\n",
    "- Convert all characters to lowercase\n",
    "- Remove punctuation signs\n",
    "</br>\n",
    "\n",
    "We won't do word lemmatization or stop-word removal as our model of choice is the Transformer which benefits from both, fully expanded tokens and also stop-words as they give context to text. So, the following function normalize lyrics:\n",
    "\n",
    "#### (Sentence-level or Token-level classification with Transformers?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['through', 'the', 'course', 'of', 'an', 'embrace', 'our', 'sisters', 'felt', 'a', 'striking', 'hand', 'their', 'fear', 'was', 'raised', 'by', 'the', 'light', 'of', 'day', 'their', 'quiet', 'rage', 'sleeps', 'with', 'them', 'tonight', 'and', 'they', 'say', 'we', 'have', 'a', 'reason', 'to', 'ban', 'our', 'heart', 'we', 'have', 'a', 'reason', 'to', 'change', 'our', 'mind', 'sister', 'midnight', 'sister', 'moon', 'like', 'me', 'so', 'much', 'do', 'not', 'think', 'i', 'will', 'see', 'them', 'soon', 'through', 'the', 'course', 'of', 'an', 'embrace', 'our', 'sisters', 'felt', 'a', 'striking', 'hand', 'their', 'fear', 'was', 'raised', 'by', 'the', 'light', 'of', 'day', 'their', 'quiet', 'rage', 'sleeps', 'with', 'them', 'tonight', 'and', 'they', 'say', 'we', 'have', 'a', 'reason', 'to', 'ban', 'our', 'heart', 'we', 'have', 'a', 'reason', 'to', 'change', 'our', 'mind', 'sister', 'midnight', 'sister', 'moon', 'like', 'me', 'so', 'much', 'do', 'not', 'think', 'i', 'will', 'see', 'them', 'soon']\n"
     ]
    }
   ],
   "source": [
    "def normalize_lyrics(lyrics):\n",
    "  expanded_words = []   \n",
    "  for word in lyrics.split():\n",
    "    # using contractions.fix to expand the shortened words\n",
    "    expanded_words.append(contractions.fix(word))  \n",
    "    \n",
    "  expanded_lyrics = ' '.join(expanded_words)\n",
    "  expanded_lyrics = re.sub(r\"in'\", \"ing\", expanded_lyrics) # taking into account verbs that end in \"in'\", singin' -> singing\n",
    "\n",
    "  tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "  tokens = tokenizer.tokenize(expanded_lyrics)\n",
    "\n",
    "  tokens = [token.lower() for token in tokens]\n",
    "  return tokens\n",
    "\n",
    "lyrics = data_train['Rock']['Lyrics'].iloc[0]\n",
    "print(normalize_lyrics(lyrics))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now do this for all samples and all categories. We will also make a new data column \"Tokens\" which will contain the tokenized lyrics to be able to compare the original and tokenized one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dict(data):\n",
    "    for key in data.keys():\n",
    "        genre_tokens = []\n",
    "        for i in range(len(data[key])):\n",
    "            genre_tokens.append(normalize_lyrics(data[key]['Lyrics'].iloc[i]))\n",
    "        data[key]['Tokens'] = genre_tokens\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = tokenize_dict(data_train)\n",
    "data_test = tokenize_dict(data_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of reusing the dataset we will save train and test data so to be able to load it without going through the preprocessing steps in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dfs(data):\n",
    "    dfs = []\n",
    "    for key in data.keys(): dfs.append(data[key])\n",
    "    return pd.concat(dfs)\n",
    "combine_dfs(data_test).to_csv('data/pruned_test.csv', index=False)\n",
    "combine_dfs(data_train).to_csv('data/pruned_train.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Model architecture </h4>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
